{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fw5s4Ta66WaR",
    "outputId": "f269df86-3139-4742-bda3-e6233d31a8f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import natsort\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Iqin4FvH6WaU"
   },
   "outputs": [],
   "source": [
    "def load_filename(path):\n",
    "    dirFiles = os.listdir(path)\n",
    "    for i, file in enumerate(dirFiles):\n",
    "        dirFiles[i] = path + file\n",
    "    return natsort.natsorted(dirFiles ,reverse=False)\n",
    "\n",
    "# load all images in a directory into memory\n",
    "def load_images(list_path, size=(256, 256)):\n",
    "    img_list = list()\n",
    "    # enumerate filenames in directory, assume all are images\n",
    "    for filename in list_path:\n",
    "        # load and resize the image\n",
    "        pixels = load_img(filename, target_size=size)\n",
    "        # convert to numpy array\n",
    "        pixels = img_to_array(pixels)\n",
    "        pixels = (pixels - 127.5) / 127.5\n",
    "        img_list.append(pixels)\n",
    "    return np.asarray(img_list)\n",
    "\n",
    "def pred_images(g_model, target_dir, filenames, batch_size=128):\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.mkdir(target_dir)\n",
    "\n",
    "    imgs = load_images(filenames)\n",
    "    g_img = g_model.predict(imgs)\n",
    "    g_img = g_img * 127.5 + 127.5\n",
    "    for j, _img in enumerate(g_img):\n",
    "        cv2.imwrite(target_dir + \"/\" + os.path.basename(filenames[j]), cv2.resize(cv2.cvtColor(_img.astype('uint8'), cv2.COLOR_RGB2BGR), (200, 250)))\n",
    "    print(\"Image has been successfully saved in \\\"\" + target_dir + \"\\\" folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Zm9HB-Rv6WaW"
   },
   "outputs": [],
   "source": [
    "filenames = load_filename('Dataset/CUHK/Testing sketch/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2rQ6698o6WaX",
    "outputId": "b9c1e89e-7e4e-462d-b11c-3e9a68034bb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\T PRUTHVIRAJ SINGH\\miniconda3\\envs\\gan\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\T PRUTHVIRAJ SINGH\\miniconda3\\envs\\gan\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\T PRUTHVIRAJ SINGH\\miniconda3\\envs\\gan\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Image has been successfully saved in \"Generated Images/Generated_Pixel[1]_Context[0]\" folder\n"
     ]
    }
   ],
   "source": [
    "g_model = load_model('Models/g_model1.h5',custom_objects={'InstanceNormalization':InstanceNormalization})\n",
    "\n",
    "pred_images(g_model, \"Generated Images/Generated_Pixel[1]_Context[0]\", filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xgIKRdvu6WaY",
    "outputId": "930cd71f-452d-42be-a681-f44c80b94235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image has been successfully saved in \"Generated Images/Generated_Pixel[08]_Context[02]\" folder\n"
     ]
    }
   ],
   "source": [
    "g_model = load_model('Models/g_model1.h5',custom_objects={'InstanceNormalization':InstanceNormalization})\n",
    "\n",
    "pred_images(g_model, \"Generated Images/Generated_Pixel[08]_Context[02]\", filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JBMHpFWX6WaZ",
    "outputId": "eb28f047-0459-4e62-f4c6-42c2782e842f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image has been successfully saved in \"Generated Images/Generated_Pixel[05]_Context[05]\" folder\n"
     ]
    }
   ],
   "source": [
    "g_model = load_model('Models/g_model1.h5',custom_objects={'InstanceNormalization':InstanceNormalization})\n",
    "\n",
    "pred_images(g_model, \"Generated Images/Generated_Pixel[05]_Context[05]\", filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "p32zTxY86Waa",
    "outputId": "58f61dd9-6fbc-4fdc-ba98-9f51d94f4ed1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image has been successfully saved in \"Generated Images/Generated_Pixel[02]_Context[08]\" folder\n"
     ]
    }
   ],
   "source": [
    "g_model = load_model('Models/g_model1.h5',custom_objects={'InstanceNormalization':InstanceNormalization})\n",
    "\n",
    "pred_images(g_model, \"Generated Images/Generated_Pixel[02]_Context[08]\", filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Testing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
